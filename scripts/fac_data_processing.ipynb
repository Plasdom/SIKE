{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import input_fac\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/power8/Documents/05_papers/01_impurities/01_analysis/')\n",
    "import sk_plotting_functions as spf\n",
    "import os\n",
    "import json\n",
    "import sike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el_sym, el in sike.utils.constants.SYMBOL2ELEMENT.items():\n",
    "    data_dir = \"/Users/power8/Documents/01_code/03_sike/OLD/Old SIKEs/11 - SIKE 2/atom_data/\" + el + \"/FAC\"\n",
    "    stages = [d for d in os.listdir(data_dir) if '_I' in d or '_V' in d or '_X' in d]\n",
    "    ex_trans = []; iz_trans = []; em_trans = []; rr_trans = []; ai_trans = []\n",
    "    uta = True\n",
    "    for s in stages:\n",
    "        print(s)\n",
    "        stage_data_dir = os.path.join(data_dir,s)\n",
    "        nlj_levels = input_fac.get_levels(os.path.join(stage_data_dir, el_sym + '_en.txt'))\n",
    "        ex_trans += input_fac.get_ex_cross_sections(os.path.join(stage_data_dir, el_sym + '_ce.txt'))\n",
    "        iz_trans += input_fac.get_iz_cross_sections(os.path.join(stage_data_dir, el_sym + '_ci.txt'))\n",
    "        em_trans += input_fac.get_em_rates(os.path.join(stage_data_dir, el_sym + '_tr.txt'), uta=uta)\n",
    "        rr_trans += input_fac.get_rr_cross_sections(os.path.join(stage_data_dir, el_sym + '_rr.txt'))\n",
    "        ai_trans += input_fac.get_ai_rates(os.path.join(stage_data_dir, el_sym + '_ai.txt'))\n",
    "    nlj_transitions = iz_trans + ex_trans + rr_trans + ai_trans + em_trans\n",
    "\n",
    "    # Output levels to json\n",
    "    with open(el_sym + '_levels_nlj.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump([l.__dict__ for l in nlj_levels], f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # Output transitions to json\n",
    "    # E_grid = nlj_transitions[0].E_grid - nlj_transitions[0].delta_E\n",
    "    for t in nlj_transitions:\n",
    "        t.make_jsonable()\n",
    "    with open(os.path.join(\"/Users/power8/Documents/01_code/03_sike/SIKE/updated_atomic_data\",el,el_sym + '_transitions_nlj.json'), 'w', encoding='utf-8') as f:\n",
    "        # json.dump([{\"E_grid\": list(E_grid)}] + [(l).__dict__ for l in nlj_transitions], f, ensure_ascii=False, indent=4)\n",
    "        json.dump([(l).__dict__ for l in nlj_transitions], f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skrun = spf.SKRun('/Users/dpower/Documents/01 - PhD/14 - ELM investigation/01 - Runs/01 - Equilibria/02 - Kinetic/P_in = 4MW/Output_job_EQ_K4_2e19')\n",
    "# skrun = spf.SKRun('/Users/power8/Documents/05_papers/01_impurities/01_analysis/data/SOL-KiT/Mid-length rundeck/Kinetic/Output_K_L3_7e19/Run_1')\n",
    "# E_grid = skrun.T_norm * (skrun.vgrid / skrun.v_th) ** 2\n",
    "# E_grid = nlj_transitions[0].E_grid\n",
    "# for t in ex_trans:\n",
    "#     t.process_cross_section(E_grid)\n",
    "# for t in iz_trans:\n",
    "#     t.process_cross_section(E_grid)\n",
    "# for t in rr_trans:\n",
    "#     t.process_cross_section(E_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot some transition cross-sections\n",
    "# trans = iz_trans\n",
    "# fig,ax = plt.subplots(1)\n",
    "# for t in trans:\n",
    "#     ax.plot(t.E_grid,t.sigma)\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate states over j\n",
    "nl_levels = input_fac.aggregate_states(nlj_levels)\n",
    "nl_transitions = input_fac.aggregate_transitions(nl_levels, nlj_levels, nlj_transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output nl-aggregated levels and transitions to json\n",
    "with open(el_sym + '_levels_nl.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump([l.__dict__ for l in nl_levels], f, ensure_ascii=False, indent=4)\n",
    "with open(el_sym + '_transitions_nl.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump([{\"E_grid\": list(E_grid)}] + [(l).__dict__ for l in nl_transitions], f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some testing (to be deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('H_transitions_nl.json') as f:\n",
    "    H0_trans = json.load(f)\n",
    "with open('H_levels_nl.json') as f:\n",
    "    H_levs = json.load(f)\n",
    "with open('He_transitions_nl.json') as f:\n",
    "    He1_trans = json.load(f)\n",
    "with open('He_levels_nl.json') as f:\n",
    "    He_levs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(H0_trans), len(He1_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,lev in enumerate(He_levs):\n",
    "    # print(i,lev['id'])\n",
    "    if i != lev['id']:\n",
    "        print(lev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0_ids = []\n",
    "for t in H0_trans[1:]:\n",
    "    trans_id = (t['from_id'], t['to_id'])\n",
    "    H0_ids.append(trans_id)\n",
    "He1_ids = []\n",
    "for t in He1_trans[1:]:\n",
    "    trans_id = (t['from_id'], t['to_id'])\n",
    "    He1_ids.append(trans_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for He1_id in He1_ids:\n",
    "    if He1_id not in H0_ids:\n",
    "        print(He1_id, 'not in H0_ids')\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f9328efe3468e6c370cdfed98702d3986faf748314d5bcec59da615d65baa7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
